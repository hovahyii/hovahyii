"use client";

import Image from 'next/image';

export default function SeedanceContent() {
    return (
        <div className="prose lg:prose-xl max-w-none">
            <div className="mb-8 p-6 rounded-2xl border border-purple-200 dark:border-purple-800 bg-gradient-to-br from-purple-50 via-white to-slate-50 dark:from-purple-950/40 dark:via-slate-900 dark:to-slate-900">
                <p className="text-sm uppercase tracking-[0.3em] text-purple-600 dark:text-purple-300 font-semibold">AI BREAKING NEWS â€¢ 2026-02-08</p>
                <h2 className="text-3xl font-extrabold mt-3 mb-4 text-slate-900 dark:text-white">ðŸ‘‘ China Has the World's #1 Model Too! Seedance 2.0: The AI That Can Be a Director</h2>
                <p className="text-lg text-slate-700 dark:text-slate-200">
                    Seedance 2.0 has been on fire for days. TikTok and Bilibili are flooded with fan-made videos, and it instantly took four spots on Weibo's tech trending list. My idol Feng Ji even posted on Weibo saying, "The childhood era of AIGC is over."
                </p>
            </div>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/yocar.jpg"
                    alt="Feng Ji Weibo"
                    width={900}
                    height={500}
                    className="rounded-2xl shadow-lg"
                />
            </div>

            <p>(I have to show off a little here, I follow my idol on Weibo hehehe...)</p>
            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/yocar profile.png"
                    alt="Weibo Profile"
                    width={900}
                    height={300}
                    className="rounded-2xl shadow-lg"
                />
            </div>

            <p>
                Back to this article, to be honest, I stumbled through writing it. Just halfway through, bam, the real person reference got banned, and all cases had to be replaced; while re-running them, bam, because it was too popular, ByteDance's servers exploded directly. Now it takes an average of 20 minutes to generate a video. And today, Seedance 2.0 on Doubao also started internal testing.
            </p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/interface.png"
                    alt="Seedance Interface"
                    width={900}
                    height={500}
                    className="rounded-2xl shadow-lg"
                />
            </div>

            <p>
                I dare not imagine what ByteDance's servers will burn like when it's officially released, given Doubao's user volume. It's too hot, really too hot, giving off a feeling like DeepSeek R1's infinite retries last year.
            </p>
            <p>
                Last year DS, this year SD, seriously, every Spring Festival, they don't let us rest properly. But finally, amidst the mess, I spent more than 2 days finishing this article.
            </p>
            <p>
                This time I won't evaluate the model's capabilities, because there's no need. This is the world's No. 1, the undisputed No. 1. Many foreigners are now frantically asking for "magic" on X, begging for Seedance 2.0 access.
            </p>
            <p>
                Testing capabilities nowâ€”whether consistency is stronger, output is higher definitionâ€”is like assessing if the sophons are made of stainless steel or have voice control while the Trisolarans are attacking. It's absurd.
            </p>
            <p>
                Actually, I'm quite anxious too. Many people might not know, besides being an AI media blogger, I have another job: AI film industrialization. Not AI shorts or comics, but movies and TV series. Yesterday I posted a thought: "Saturday night, I sent it to some friends in the film industry and crew members. I said this time the sky might really be changing. I'm anxious too, because our so-called AI film industrialization, in an instant, turned to ashes."
            </p>
            <p>
                Then a friend commented: "'Industrialization turning to ashes' might be saying it too early."
            </p>
            <p>Here is how I replied:</p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/maths.png"
                    alt="Reply Comment"
                    width={900}
                    height={500}
                    className="rounded-2xl shadow-lg"
                />
            </div>

            <p>
                Looking back at this year and a half, I've met many good partners, but looking back at our technological iteration along the way, it's really a sigh. Only when you have been personally fucked over and replaced, watching everything you desperately built turn into bubbles, can you understand that feeling.
            </p>
            <p>
                It's like a country fighting a huge war. The emperor sends all his soldiers to this war. On the front line, countless high-spirited, hot-blooded heavy armored soldiers, riding warhorses, holding spears, fully armed, start advancing. Everyone wants to try hard to win this war. They are invincible all the way, stepping into the opponent's city wall, only to find not a single soldier. In the center of the city, there is only a huge metal iron ball. It's called a nuclear bomb.
            </p>
            <p>
                In that instant, the nuclear bomb was detonated.
            </p>
            <p>
                In that instant, with the entire city as the midpoint, this elite force supplied by millions of people in the rear, the force that was invincible on the original continent, was instantly vaporized in a ten-thousandth of a second, disappearing without a trace.
            </p>
            <p>
                You ask me how I feel? I am one of the vaporized troops. What feeling can I have? I know, the moment I disappeared, I might not even know what happened.
            </p>
            <p>The train of the times rolls forward; it waits for no one.</p>
            <p>Facing this scene, I can only say, since the road ahead is irreversible, just keep walking.</p>
            <p>
                So, my mood is complicated, excited and anxious, really quite contradictory. In this article, I won't do a review. I just want to throw out a brick to attract jade, showing everyone the fun ways Seedance 2.0 can be played with right now.
            </p>
            <p>I hope everyone gets on the train of the new era and enjoys the scenery along the way.</p>
            <p>Sit tight and hold on, we are driving now.</p>

            <h3 className="text-2xl font-bold mt-12 mb-6">1. Director Mindset</h3>
            <p>
                Actually, a big reason why Seedance 2.0 exploded this time is its director mindset.
            </p>
            <p>
                In the past, when we played with AI video, often two things got stuck: one is the story, the other is the storyboard. These two things make the gap between AI videos made by ordinary people and those made by professionals very large. Use script is the embodiment of the screenwriter's will, and the storyboard is the core element of visualizing the script.
            </p>
            <p>
                For example, a sentence in the script: "Xiao Ming pushed the door open, saw the mess in the room, and was stunned."
            </p>
            <p>
                For this sentence, a director can have countless ways to shoot it.
            </p>
            <ul className="list-disc pl-6 mb-6">
                <li>You can first give a medium shot of Xiao Ming pushing the door, then cut to a panoramic view of the room showing the mess, and then cut back to a close-up of Xiao Ming's expression.</li>
                <li>You can also use a long take, following Xiao Ming's perspective to push in, letting the audience discover the situation in the room with Xiao Ming.</li>
                <li>You can also first show the mess in the room, then a close-up of the door handle turning, then Xiao Ming's footsteps, and finally Xiao Ming's face.</li>
            </ul>
            <p>
                In the past, AI video had almost no way to help you solve the storyboard problem. We almost always used the image-to-video workflow, that is, one image corresponds to a 4s clip, and then various clips are edited together to become a film.
            </p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/excel.png"
                    alt="AI Video Workflow Excel"
                    width={900}
                    height={500}
                    className="rounded-2xl shadow-lg"
                />
            </div>
            <p className="text-center text-sm text-slate-500 mt-2">This is a collaborative document for an AI film made in early 2024. It really looked like this.</p>

            <p>
                You will see that AI's core ability is actually to dynamically animate your storyboard images, that's all. Later, Sora 2 completely democratized storyboarding. You only need an image and a paragraph, and AI can help you fill in the storyboard to become a decent little story, but that storyboard was actually a mess of cuts without rules.
            </p>
            <p>
                But Seedance 2.0 almost solved the storyboard problem. In terms of lens aesthetics, it is a generation ahead of Sora, and can output sound and BGM directly (although I often manually turn off BGM with Prompt).
            </p>
            <p>Like this case:</p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/image.png"
                    alt="Seedance Case"
                    width={900}
                    height={500}
                    className="rounded-xl shadow"
                />
            </div>

            <p>
                Mainly wrote some plot and dialogue, and it solved all the storyboards by itself. The video looks like this.
            </p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/old school.jpg"
                    alt="Old School Video"
                    width={900}
                    height={500}
                    className="rounded-xl shadow"
                />
            </div>

            <p>
                Honestly, this quality can already pass for real in the TV drama field, even better than some trashy ancient costume dramas. The characters are extremely natural, the lines are good enough, and every cut has meaning.
            </p>
            <p>
                And another story allows you to perfectly feel what "director mindset" is. My Prompt has only a simple little story:
            </p>
            <blockquote className="pl-4 border-l-4 border-purple-500 italic my-4">
                He trained hard for twenty years and finally stood on the final stage of the World Martial Arts Competition. Facing the Thai boxing champion, the whole audience held their breath. With the referee's command, he sank his Qi into his Dantian and used his lifelong learningâ€”â€”
                Knelt down and shouted "Dad".
                The champion was stunned.
                One punch, he won.
            </blockquote>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/prompt.png"
                    alt="Prompt Example"
                    width={900}
                    height={300}
                    className="rounded-xl shadow"
                />
            </div>

            <p>
                And let's see Seedance 2.0's final video and the storyboard it gave. It's too outrageous.
            </p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/sun.jpg"
                    alt="Martial Arts Video"
                    width={900}
                    height={500}
                    className="rounded-xl shadow"
                />
            </div>

            <p>
                This thing, it really understands drama... It knows when to give a close-up to emphasize emotion, when to pull the lens to explain the environment, when to slow down to create tension, and when to quick cut to accelerate the rhythm.
            </p>
            <p>
                These things used to require professional directors to control.
                Now, AI can do it.
                And it can direct output sound and BGM.
                It even did the editing work. Too outrageous.
            </p>

            <h3 className="text-2xl font-bold mt-12 mb-6">2. Storyboard Replication</h3>
            <p>
                In the film and television industry, because storyboards are particularly important, there has always been a learning method called "pulling films" (scene breakdown). It is to let everyone learn lens scheduling, layout, and emotional use. So, learning the lens scheduling of excellent masters and excellent works is very important.
            </p>
            <p>
                In the past, it was hard for us to imitate a work of this type. But now, because Seedance 2.0 supports video reference, this matter has become very simple.
            </p>
            <p>
                For example, I like this storyboard segment from "Weathering with You." And now, we just need to throw this video in, let it reference it, and generate a new story for me. It's very convenient.
            </p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/anime.gif"
                    alt="Anime Reference"
                    width={900}
                    height={500}
                    className="rounded-xl shadow"
                    unoptimized
                />
            </div>

            <p>
                And not just plot and story storyboards, even in commercials, you can use it. For example, I directly use a car's storyboard and camera movement, plus a picture of DJI, to replicate one for it.
            </p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/car.gif"
                    alt="Car Commercial Reference"
                    width={900}
                    height={500}
                    className="rounded-xl shadow"
                    unoptimized
                />
            </div>

            <p>
                Now, everyone can shoot a million-dollar blockbuster with just one picture... Let me mention this separately, if you use the Doubao internal beta version, it doesn't support uploading video references yet. I guess Doubao's user volume is too huge, gotta wait a bit.
            </p>

            <h3 className="text-2xl font-bold mt-12 mb-6">3. Classic Fan Formations (Secondary Creation)</h3>
            <p>
                Humanity's deepest love for their IPs is making fan creations (secondary creations) for them. In the past, it was quite hard. For example, if you wanted to make a fan video for "Chicken You Are So Beautiful," you might really have to hand-rub an MV, or start from 0 to make a video. So, past fan creations often concentrated on fan fiction and images.
            </p>
            <p>
                But it's different now.
            </p>
            <p>
                I've been browsing TikTok and Bilibili these past two days and found that fan creations have gone completely crazy. Abstract and high-octane coexist.
            </p>
            <p>For example, this one I saw on X, it exploded.</p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/fight.jpg"
                    alt="Fight Scene"
                    width={900}
                    height={500}
                    className="rounded-xl shadow"
                />
            </div>

            <p>
                And it's all my cup of tea. Just a year ago, you wouldn't dare to think about these things. Although AI back then was awesome, it couldn't produce this level of camera movement.
            </p>
            <p>
                And if you are not satisfied with the ending of a story you like, you can also modify it yourself. For example, at the end of "Stranger Things" Season 5, I really hope, really hope Eleven can come back. Then, we can replicate one ourselves.
            </p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/strangerthing.png"
                    alt="Stranger Things Fan Edit"
                    width={900}
                    height={500}
                    className="rounded-xl shadow"
                />
            </div>

            <p>She really, came back.</p>

            <p>
                Really, not only can you do warm stuff, but abstract stuff is flying everywhere. For example, this man can enter the world of Demon Slayer and have a hearty battle.
            </p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/ghost.jpg"
                    alt="Demon Slayer Abstract"
                    width={900}
                    height={500}
                    className="rounded-xl shadow"
                />
            </div>

            <p>Feels better looking than Demon Slayer itself... Direct output with one sentence, truly infinite creativity.</p>

            <h3 className="text-2xl font-bold mt-12 mb-6">4. Editing Reality</h3>
            <p>
                Since it can reference videos, naturally, there is a very special function, which is editing reality. Extremely useful for video post-production.
            </p>
            <p>
                In the past, we've all heard a saying, you could even say a truth: Videos can't be Photoshopped.
            </p>
            <p>
                But now, who says videos can't be P'd?
            </p>
            <p>
                For example, I just casually shot a 10-second waving video, then in Seedance, added a little Prompt:
            </p>
            <p>A very realistic Pokemon summoning video is done.</p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/pokemon.jpg"
                    alt="Pokemon Summoning"
                    width={900}
                    height={500}
                    className="rounded-xl shadow"
                />
            </div>

            <p>
                Really, various physical laws and stuff, it's really quite cool.
            </p>
            <p>
                Then I filmed our company corridor at 1 AM.
                Directly used Prompt to change the style, instantly turning it into the Otherworld. This video has a high-energy warning at the back, pay attention when opening.
            </p>

            <p>
                This effect is stable to the point of explosion, why do we need post-production special effects anymore?
            </p>

            <h3 className="text-2xl font-bold mt-12 mb-6">5. Generating Vlogs from Assets</h3>
            <p>
                A very magical way to play, I feel it can even impact CapCut a bit. It is that we shoot a lot of assets daily, right? For example, I want to generate a vlog very simply from these assets. In the past, you might have to use templates.
            </p>
            <p>
                But in the AI world, you really, just speak.
            </p>
            <p>
                For example, a few days ago in our team, a kid took some photos, we threw them directly to Seedance 2.0.
            </p>
            <p>
                Then it can directly output a pretty fun vlog. All pictures will move, and it will automatically identify what the picture is, adding small decorations. Quite interesting.
            </p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/new year.gif"
                    alt="Vlog Generation"
                    width={900}
                    height={500}
                    className="rounded-xl shadow"
                    unoptimized
                />
            </div>

            <h3 className="text-2xl font-bold mt-12 mb-6">6. E-commerce Ads</h3>
            <p>
                This gameplay might be the one that can monetize most directly. Friends who have done e-commerce should know that shooting product videos is a very troublesome thing. You need to find a venue, find a model, find a photographer, find a lighter. Tossing around for a day might only get tens of seconds of footage, and it might not even be usable. And every product has to be shot separately, the cost is very high.
            </p>
            <p>
                But now, Seedance 2.0 gives a new possibility.
            </p>
            <p>
                You can use AI to generate product display videos. I tried it, the effect was unexpectedly good. For example, this product, a very magical face cream.
            </p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/khazix.jpg"
                    alt="Product Demo"
                    width={900}
                    height={500}
                    className="rounded-xl shadow"
                />
            </div>

            <p>We can let an AI model explain it.</p>
            <p>I really think it's more natural, better looking, and more comfortable than many real people. Why do we need real people anymore?</p>
            <p>Even, you can let Voldemort endorse rhinitis special medicine at the US Super Bowl.</p>
            <p>The last scene, I ask you if it is holy or not.</p>

            <h3 className="text-2xl font-bold mt-12 mb-6">7. Subject Migration</h3>
            <p>
                This function, to be honest, is the one I find most outrageously effective. But it is indeed a very useful function for the film and television industry.
            </p>
            <p>
                You can migrate your own photo to a certain subject in another video, completing identical movement and lip-sync replication.
            </p>
            <p>
                That is the motion capture we rumored about. Only now motion capture doesn't need wearing so much complex equipment. Just a video, a photo, migrate everything.
            </p>
            <p>
                For example, a camera movement video that exploded recently because of Seedance 2.0.
            </p>

            <div className="my-8 flex justify-center">
                <Image
                    src="/blog/seedance/compare.gif"
                    alt="Subject Migration"
                    width={900}
                    height={500}
                    className="rounded-xl shadow"
                    unoptimized
                />
            </div>

            <p>
                It is really a perfect replica, restoring exactly the same for you, even restoring the occlusion relationship. Honestly, I have never seen such outrageous motion migration. In terms of overall migration and replication capabilities, it should be the best in the world right now.
            </p>

            <h3 className="text-2xl font-bold mt-12 mb-6">Final Words</h3>
            <p>
                Writing till here, this article is about to wrap up. These are roughly some of the ways to play Seedance 2.0, throwing out a brick to attract jade.
            </p>
            <p>
                In the context that real person appearance needs verification, real person reference probably won't be opened in the short term. Methods similar to Doubao Avatar Video will be used, likely the mainstream gameplay for C-end users for a long time.
            </p>
            <p>
                Wait until New Year's Eve, when Doubao shows off Seedance 2.0's effect on the Spring Festival Gala, when everyone pours into Doubao to try creation, try AI video. The entire society's perception of AI video might be accelerated forward by a large chunk.
            </p>
            <p>
                Looking back a few years, it's really too magical. This video should execute the speed of AI evolution very well.
            </p>

            <p>
                My own mood is also very complicated. As an AI media blogger, I am of course excited. This is an epoch-making product. It gave me countless topics, countless contents to write.
            </p>
            <p>
                But as a person doing AI film industrialization, I am very anxious. The workflow we painstakingly built in the crew for a year and a half, the experience accumulated, might be wasted in this update. This feeling is hard to describe. It's like you worked hard to climb a mountain, about to reach the top, suddenly found someone opened a cable car directly to the top, and the ticket price is particularly cheap.
            </p>
            <p>
                Will you feel your previous efforts were silly? You will.
            </p>
            <p>
                But what can you do? Only adjust your mindset, accept reality, and then figure out how to use this cable car to go to a higher place.
            </p>
            <p>
                I said in my short article the day before yesterday, the train of the times rolls forward, it will not wait for anyone. This sentence sounds a bit depressing, but I think it is also an incentive. Since the train doesn't wait for people, then run fast, jump on it quickly. No matter what you did before, no matter what you accumulated before, now you have to start learning again, re-adapting to new tools and new rules.
            </p>
            <p>
                This is the challenge this era gives to everyone, and also the opportunity.
            </p>
            <p>
                I saw some people in the comment section saying they feel they are going to lose their jobs. I want to say, don't be so pessimistic. Every technological revolution will eliminate some jobs, but will also create some new jobs. Cars eliminated coachmen, but created drivers, car mechanics, gas station employees. Computers eliminated typists, but created programmers, designers, self-media people. AI will eliminate some jobs, but it will definitely create some new jobs.
            </p>
            <p>
                The key is, you have to become the one who can seize new opportunities, not the one being eliminated. Maintain curiosity, keep learning, keep sensitive to new things.
            </p>
            <p>
                Seedance 2.0 is released, go play with it, study it, think about what it can be used for. Don't wait for others to teach you, don't wait for the market to mature, don't wait for everything to be clear before acting. When you figure it out, there won't be opportunities anymore.
            </p>
            <p>
                Hope this article, these few gameplays, can give everyone some inspiration. I also hope everyone can find their own place in this crazy era.
            </p>
            <p>
                Finally, let's borrow Teacher Feng Ji's words as the ending:
            </p>
            <p className="text-xl font-bold text-center mt-8">
                The childhood era of AIGC is over.
                Welcome to the Youth Era of AIGC.
            </p>
        </div>
    );
}
